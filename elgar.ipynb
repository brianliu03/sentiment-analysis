{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from transformers import pipeline\n",
    "from text_stop_sentences import text_stop_sentences\n",
    "from tgs_manual import get_tgs_manual\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import mytextgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of each item in all textgrids\n",
    "tgs = []\n",
    "for f in sorted(listdir('force_aligned/manual')):\n",
    "    if isfile(join('force_aligned/manual', f)):\n",
    "        tg = mytextgrid.read_from_file(join('force_aligned/manual', f)).to_dict()['tiers'][0]['items']\n",
    "        for item in tg:\n",
    "            tgs.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of words in file force_aligned/gentle/01_1/transcript.txt\n",
    "words = []\n",
    "with open('force_aligned/gentle/01_1/transcript.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        words.append(line.replace('.', '').split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/brianliu03/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# get model results\n",
    "df_stop_sentences = text_stop_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add start and end times to df_stop_sentences\n",
    "idx = 0\n",
    "for i in range(len(tgs)):\n",
    "    if tgs[i]['text'] != '':\n",
    "        df_stop_sentences.loc[idx, 'start'] = tgs[i]['xmin']\n",
    "        df_stop_sentences.loc[idx, 'end'] = tgs[i]['xmax']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
